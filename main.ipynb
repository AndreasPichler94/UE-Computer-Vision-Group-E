{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No invalid sequences found.\n",
      "Total sequences after renaming: 3131\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_4_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_0_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_8_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_1_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_Parameters.txt\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_7_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_GT_pose_0_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_5_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_9_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_10_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_3_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_6_thermal.png\n",
      "File not found: C:\\Users\\andreaspichler\\Desktop\\Part1\\0_0_pose_2_thermal.png\n",
      "Data split into 80.0% training (2505 Sequences) and 20.0% validation (626 Sequences).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "last_valid_sequence = 0\n",
    "\n",
    "def split_data(total_sequences, train_percentage):\n",
    "    if not os.path.exists(training_data_path):\n",
    "        os.makedirs(training_data_path)\n",
    "\n",
    "    if not os.path.exists(validation_data_path):\n",
    "        os.makedirs(validation_data_path)\n",
    "\n",
    "    train_size = round(total_sequences * train_percentage)\n",
    "\n",
    "    # Copy files according to the split into training and validation data directories.\n",
    "    for current_index in range(1, total_sequences):\n",
    "        expected_files = get_expected_files(current_index)\n",
    "\n",
    "        if current_index < train_size:\n",
    "            destination_path = training_data_path\n",
    "        else:\n",
    "            destination_path = validation_data_path\n",
    "\n",
    "        for expected_file in expected_files:\n",
    "            source_path = os.path.join(raw_directory_path, expected_file)\n",
    "            destination_file = os.path.join(destination_path, os.path.basename(expected_file))\n",
    "\n",
    "            # Check if the file exists before attempting to move it\n",
    "            if os.path.exists(source_path):\n",
    "                shutil.move(source_path, destination_file)\n",
    "            else:\n",
    "                print(f\"File not found: {source_path}\")\n",
    "    if not last_valid_sequence == 0:\n",
    "        print(f\"Data split into {train_percentage * 100}% training ({train_size} Sequences) and {100 - train_percentage * 100}% validation ({total_sequences - train_size} Sequences).\")\n",
    "\n",
    "def get_expected_files(current_index):\n",
    "    expected_files = set()\n",
    "\n",
    "    for i in range(11):\n",
    "        expected_files.add(f'0_{current_index}_pose_{i}_thermal.png')\n",
    "\n",
    "    expected_files.add(f'0_{current_index}_Parameters.txt')\n",
    "    expected_files.add(f'0_{current_index}_GT_pose_0_thermal.png')\n",
    "\n",
    "    return expected_files\n",
    "\n",
    "def rename_files(current_index):\n",
    "    expected_files = get_expected_files(current_index)\n",
    "    for expected_file in expected_files:\n",
    "        old_path = os.path.join(raw_directory_path, expected_file)\n",
    "        new_index = last_valid_sequence + 1\n",
    "        new_file = expected_file.replace(f'0_{current_index}', f'0_{new_index}')\n",
    "        new_path = os.path.join(raw_directory_path, new_file)\n",
    "        os.rename(old_path, new_path)\n",
    "    #print(f\"Renamed sequences with index {current_index} to {last_valid_sequence + 1}\")\n",
    "    return new_index\n",
    "\n",
    "def cleanup_data():\n",
    "    global last_valid_sequence\n",
    "    invalid_sequences_found = False\n",
    "\n",
    "    file_count = len([f for f in os.listdir(raw_directory_path) if os.path.isfile(os.path.join(raw_directory_path, f))])\n",
    "    approximated_sequences = math.ceil(file_count / 13)\n",
    "\n",
    "    for current_index in range(approximated_sequences):\n",
    "        expected_files = get_expected_files(current_index)\n",
    "        missing_file = None\n",
    "        found_files = [file_name for file_name in expected_files if\n",
    "                       os.path.exists(os.path.join(raw_directory_path, file_name))]\n",
    "\n",
    "        if len(found_files) > 0:\n",
    "            for file_name in expected_files:\n",
    "                full_path = os.path.join(raw_directory_path, file_name)\n",
    "                if not os.path.exists(full_path):\n",
    "                    missing_file = file_name\n",
    "                    break\n",
    "\n",
    "            if missing_file is not None:\n",
    "                invalid_sequences_found = True\n",
    "                for delete_file in expected_files:\n",
    "                    delete_path = os.path.join(raw_directory_path, delete_file)\n",
    "                    if os.path.exists(delete_path):\n",
    "                        os.remove(delete_path)\n",
    "                print(f\"Sequence {current_index} deleted due to missing file: {missing_file}\")\n",
    "            else:\n",
    "                if current_index != 0 and (current_index - last_valid_sequence) > 1:\n",
    "                    last_valid_sequence = rename_files(current_index)\n",
    "                else:\n",
    "                    last_valid_sequence = current_index\n",
    "\n",
    "    if not invalid_sequences_found:\n",
    "        print(\"No invalid sequences found.\")\n",
    "\n",
    "    if not last_valid_sequence == 0:\n",
    "        print(f\"Total sequences after renaming: {last_valid_sequence}\")\n",
    "    return last_valid_sequence + 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    raw_directory_path = os.path.join(os.path.abspath(os.path.join(os.path.abspath(__file__), '..', '..', '..')), 'data')\n",
    "    training_data_path = os.path.join(os.path.abspath(os.path.join(os.path.abspath(__file__), '..', '..', '..')), 'train')\n",
    "    validation_data_path = os.path.join(os.path.abspath(os.path.join(os.path.abspath(__file__), '..', '..', '..')), 'test')\n",
    "    train_percentage = 0.8\n",
    "\n",
    "    total_sequences = cleanup_data()\n",
    "    split_data(total_sequences, train_percentage)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T19:21:59.216563Z",
     "start_time": "2023-12-21T19:20:41.518315500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-21T16:47:28.225383600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-21T16:47:28.229390200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
